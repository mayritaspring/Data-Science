{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import time\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import lightgbm as lgb\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Set path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_path = \"/Users/mayritaspring/Desktop/Github/Home-Credit-Default-Risk/\"\n",
    "os.chdir(default_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "application_train = pd.read_csv('../Kaggle data/application_train.csv')\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "def label_encoder(input_df, encoder_dict=None):\n",
    "    \"\"\" Process a dataframe into a form useable by LightGBM \"\"\"\n",
    "    # Label encode categoricals\n",
    "    categorical_feats = input_df.columns[input_df.dtypes == 'object']\n",
    "    for feat in categorical_feats:\n",
    "        encoder = LabelEncoder()\n",
    "        input_df[feat] = encoder.fit_transform(input_df[feat].fillna('NULL'))\n",
    "    return input_df, categorical_feats.tolist(), encoder_dict\n",
    "application_train, categorical_feats, encoder_dict = label_encoder(application_train)\n",
    "X = application_train.drop('TARGET', axis=1)\n",
    "y = application_train.TARGET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. LightGBM (with Bayesian Optimization)\n",
    "### Step 1: parameters to be tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_eval(num_leaves, feature_fraction, bagging_fraction, max_depth, lambda_l1, lambda_l2, min_split_gain, min_child_weight):\n",
    "    params = {'application':'binary','num_iterations':4000, 'learning_rate':0.05, 'early_stopping_round':100, 'metric':'auc'}\n",
    "    params[\"num_leaves\"] = round(num_leaves)\n",
    "    params['feature_fraction'] = max(min(feature_fraction, 1), 0)\n",
    "    params['bagging_fraction'] = max(min(bagging_fraction, 1), 0)\n",
    "    params['max_depth'] = round(max_depth)\n",
    "    params['lambda_l1'] = max(lambda_l1, 0)\n",
    "    params['lambda_l2'] = max(lambda_l2, 0)\n",
    "    params['min_split_gain'] = min_split_gain\n",
    "    params['min_child_weight'] = min_child_weight\n",
    "    cv_result = lgb.cv(params, train_data, nfold=n_folds, seed=random_seed, stratified=True, verbose_eval =200, metrics=['auc'])\n",
    "    return max(cv_result['auc-mean'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Set the range for each parameter\n",
    "#### Make the range as narrow as possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbBO = BayesianOptimization(lgb_eval, {'num_leaves': (24, 45),\n",
    "                                        'feature_fraction': (0.1, 0.9),\n",
    "                                        'bagging_fraction': (0.8, 1),\n",
    "                                        'max_depth': (5, 8.99),\n",
    "                                        'lambda_l1': (0, 5),\n",
    "                                        'lambda_l2': (0, 3),\n",
    "                                        'min_split_gain': (0.001, 0.1),\n",
    "                                        'min_child_weight': (5, 50)}, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Bayesian Optimization: Maximize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lgbBO.maximize(init_points=init_round, n_iter=opt_round)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Get the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lgbBO.res['max']['max_params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Put all together\n",
    "X = application_train.drop('TARGET', axis=1)\n",
    "y = application_train.TARGET\n",
    "def bayes_parameter_opt_lgb(X, y, init_round=15, opt_round=25, n_folds=5, random_seed=6, n_estimators=10000, learning_rate=0.05, output_process=False):\n",
    "    # prepare data\n",
    "    train_data = lgb.Dataset(data=X, label=y, categorical_feature = categorical_feats, free_raw_data=False)\n",
    "    # parameters\n",
    "    def lgb_eval(num_leaves, feature_fraction, bagging_fraction, max_depth, lambda_l1, lambda_l2, min_split_gain, min_child_weight):\n",
    "        params = {'application':'binary','num_iterations': n_estimators, 'learning_rate':learning_rate, 'early_stopping_round':100, 'metric':'auc'}\n",
    "        params[\"num_leaves\"] = int(round(num_leaves))\n",
    "        params['feature_fraction'] = max(min(feature_fraction, 1), 0)\n",
    "        params['bagging_fraction'] = max(min(bagging_fraction, 1), 0)\n",
    "        params['max_depth'] = int(round(max_depth))\n",
    "        params['lambda_l1'] = max(lambda_l1, 0)\n",
    "        params['lambda_l2'] = max(lambda_l2, 0)\n",
    "        params['min_split_gain'] = min_split_gain\n",
    "        params['min_child_weight'] = min_child_weight\n",
    "        cv_result = lgb.cv(params, train_data, nfold=n_folds, seed=random_seed, stratified=True, verbose_eval =200, metrics=['auc'])\n",
    "        return max(cv_result['auc-mean'])\n",
    "    # range \n",
    "    lgbBO = BayesianOptimization(lgb_eval, {'num_leaves': (24, 45),\n",
    "                                            'feature_fraction': (0.1, 0.9),\n",
    "                                            'bagging_fraction': (0.8, 1),\n",
    "                                            'max_depth': (5, 8.99),\n",
    "                                            'lambda_l1': (0, 5),\n",
    "                                            'lambda_l2': (0, 3),\n",
    "                                            'min_split_gain': (0.001, 0.1),\n",
    "                                            'min_child_weight': (5, 50)}, random_state=0)\n",
    "    # optimize\n",
    "    lgbBO.maximize(init_points=init_round, n_iter=opt_round)\n",
    "    \n",
    "    # output optimization process\n",
    "    if output_process==True: lgbBO.points_to_csv(\"bayes_opt_result.csv\")\n",
    "    \n",
    "    # return best parameters\n",
    "    return lgbBO.res['max']['max_params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mInitialization\u001b[0m\n",
      "\u001b[94m------------------------------------------------------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   bagging_fraction |   feature_fraction |   lambda_l1 |   lambda_l2 |   max_depth |   min_child_weight |   min_split_gain |   num_leaves | \n",
      "    1 | 00m18s | \u001b[35m   0.74761\u001b[0m | \u001b[32m            0.9583\u001b[0m | \u001b[32m            0.6167\u001b[0m | \u001b[32m     4.8931\u001b[0m | \u001b[32m     1.9198\u001b[0m | \u001b[32m     5.3476\u001b[0m | \u001b[32m           32.7936\u001b[0m | \u001b[32m          0.0272\u001b[0m | \u001b[32m     35.5251\u001b[0m | \n",
      "    2 | 00m13s | \u001b[35m   0.74885\u001b[0m | \u001b[32m            0.9058\u001b[0m | \u001b[32m            0.4501\u001b[0m | \u001b[32m     3.9958\u001b[0m | \u001b[32m     0.4301\u001b[0m | \u001b[32m     5.0807\u001b[0m | \u001b[32m           32.5443\u001b[0m | \u001b[32m          0.0776\u001b[0m | \u001b[32m     39.0190\u001b[0m | \n",
      "    3 | 00m17s | \u001b[35m   0.74990\u001b[0m | \u001b[32m            0.9136\u001b[0m | \u001b[32m            0.8134\u001b[0m | \u001b[32m     2.3074\u001b[0m | \u001b[32m     2.8340\u001b[0m | \u001b[32m     8.3222\u001b[0m | \u001b[32m           32.7620\u001b[0m | \u001b[32m          0.0462\u001b[0m | \u001b[32m     36.6580\u001b[0m | \n",
      "    4 | 00m16s | \u001b[35m   0.75006\u001b[0m | \u001b[32m            0.9851\u001b[0m | \u001b[32m            0.8709\u001b[0m | \u001b[32m     3.9026\u001b[0m | \u001b[32m     1.5655\u001b[0m | \u001b[32m     8.1048\u001b[0m | \u001b[32m           47.4687\u001b[0m | \u001b[32m          0.0573\u001b[0m | \u001b[32m     35.4425\u001b[0m | \n",
      "    5 | 00m16s | \u001b[35m   0.75089\u001b[0m | \u001b[32m            0.8142\u001b[0m | \u001b[32m            0.4068\u001b[0m | \u001b[32m     0.5914\u001b[0m | \u001b[32m     1.2440\u001b[0m | \u001b[32m     8.4713\u001b[0m | \u001b[32m           35.6819\u001b[0m | \u001b[32m          0.0029\u001b[0m | \u001b[32m     32.8968\u001b[0m | \n",
      "\u001b[31mBayesian Optimization\u001b[0m\n",
      "\u001b[94m------------------------------------------------------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   bagging_fraction |   feature_fraction |   lambda_l1 |   lambda_l2 |   max_depth |   min_child_weight |   min_split_gain |   num_leaves | \n",
      "    6 | 00m29s | \u001b[35m   0.75122\u001b[0m | \u001b[32m            0.8824\u001b[0m | \u001b[32m            0.2785\u001b[0m | \u001b[32m     0.0636\u001b[0m | \u001b[32m     2.2423\u001b[0m | \u001b[32m     5.8154\u001b[0m | \u001b[32m           49.1417\u001b[0m | \u001b[32m          0.0100\u001b[0m | \u001b[32m     44.1038\u001b[0m | \n",
      "    7 | 00m36s | \u001b[35m   0.75131\u001b[0m | \u001b[32m            0.9785\u001b[0m | \u001b[32m            0.8560\u001b[0m | \u001b[32m     0.2812\u001b[0m | \u001b[32m     0.0292\u001b[0m | \u001b[32m     8.9339\u001b[0m | \u001b[32m           49.9035\u001b[0m | \u001b[32m          0.0821\u001b[0m | \u001b[32m     43.8205\u001b[0m | \n",
      "    8 | 00m33s | \u001b[35m   0.75166\u001b[0m | \u001b[32m            0.9212\u001b[0m | \u001b[32m            0.2732\u001b[0m | \u001b[32m     0.2660\u001b[0m | \u001b[32m     1.9191\u001b[0m | \u001b[32m     8.8121\u001b[0m | \u001b[32m            5.3852\u001b[0m | \u001b[32m          0.0012\u001b[0m | \u001b[32m     44.5129\u001b[0m | \n",
      "    9 | 00m31s |    0.73409 |             0.8018 |             0.1068 |      4.9587 |      2.9412 |      8.6253 |            39.9238 |           0.0773 |      44.9553 | \n",
      "   10 | 00m30s |    0.74762 |             0.8871 |             0.7749 |      0.3189 |      0.4824 |      5.3296 |             5.3105 |           0.0562 |      25.0965 | \n",
      "   11 | 00m31s |    0.74755 |             0.9459 |             0.8495 |      0.8824 |      2.9314 |      5.1176 |            49.9633 |           0.0341 |      24.0223 | \n",
      "   12 | 00m30s |    0.74780 |             0.8840 |             0.8662 |      0.3931 |      0.0145 |      5.0739 |             5.3169 |           0.0658 |      41.4870 | \n",
      "   13 | 00m31s |    0.74997 |             0.9101 |             0.8600 |      4.9105 |      1.7085 |      8.9306 |             5.3815 |           0.0019 |      32.6167 | \n",
      "   14 | 00m32s |    0.74996 |             0.9629 |             0.8443 |      0.7885 |      0.0156 |      8.9880 |            13.5156 |           0.0184 |      32.2845 | \n",
      "   15 | 00m29s |    0.74793 |             0.9969 |             0.8076 |      0.6626 |      0.0229 |      5.0210 |            44.9239 |           0.0965 |      36.0874 | \n",
      "{'num_leaves': 44.5128763937431, 'feature_fraction': 0.27316703970109457, 'bagging_fraction': 0.9211518733760382, 'max_depth': 8.812133310296135, 'lambda_l1': 0.2659545277553027, 'lambda_l2': 1.919145104588522, 'min_split_gain': 0.001240012334832612, 'min_child_weight': 5.385235721690251}\n"
     ]
    }
   ],
   "source": [
    "opt_params = bayes_parameter_opt_lgb(X, y, init_round=5, opt_round=10, n_folds=3, random_seed=6, n_estimators=100, learning_rate=0.05)\n",
    "print(opt_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
